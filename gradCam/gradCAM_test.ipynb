{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gradCAM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ubr4oSPpW8TW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "outputId": "bb2214e2-9402-4996-c1e2-cf5101deead4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-65f9a420a3f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# model = VGG16(weights=\"imagenet\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0mheatmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradCAM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-65f9a420a3f9>\u001b[0m in \u001b[0;36mgradCAM\u001b[0;34m(model, x)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mlast_conv_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'block5_conv3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_conv_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mpooled_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0miterate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpooled_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_conv_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mpooled_grads_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_layer_output_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(x, axis, keepdims)\u001b[0m\n\u001b[1;32m   2663\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmean\u001b[0m \u001b[0mof\u001b[0m \u001b[0melements\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2664\u001b[0m   \"\"\"\n\u001b[0;32m-> 2665\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2666\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2667\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'dtype'"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import models\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Using Google Colab\n",
        "\n",
        "IMG_PATH = '/content/drive/MyDrive/ann_project/amerry-kano--------------------/amerry_train/IMG_1447.jpeg'\n",
        "MODEL_PATH = \"/content/drive/MyDrive/ann_project/result_model/amka2_categorical_fine_tuning.h5\"\n",
        "\n",
        "img_path = IMG_PATH\n",
        "img = image.load_img(img_path, target_size=(64, 64))\n",
        "img_tensor = image.img_to_array(img)\n",
        "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "img_tensor = preprocess_input(img_tensor)\n",
        "\n",
        "model = models.load_model(MODEL_PATH)\n",
        "# model.summary()\n",
        "# cl = model.layers[0]\n",
        "# cl.summary()\n",
        "\n",
        "def deprocess_image(x):\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + 1e-5)\n",
        "    x *= 0.1\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "    x *= 255\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "def draw_activation(activation, figure_name):\n",
        "    images_per_row = 16\n",
        "    n_features = activation.shape[-1]\n",
        "    size = activation.shape[1]\n",
        "    n_cols = n_features // images_per_row\n",
        "    display_grid = np.zeros((size*n_cols, images_per_row*size))\n",
        "    for col in range(n_cols):\n",
        "        for row in range(images_per_row):\n",
        "            channel_image = activation[0, :, :, col*images_per_row+row]\n",
        "            channel_image = deprocess_image(channel_image)\n",
        "            display_grid[col*size:(col+1)*size, row*size:(row+1)*size] = channel_image\n",
        "    scale = 1./size\n",
        "    plt.figure(figsize=(scale*display_grid.shape[1], scale*display_grid.shape[0]))\n",
        "    plt.title(figure_name)\n",
        "    plt.grid(False)\n",
        "    plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
        "    plt.show()\n",
        "\n",
        "def gradCAM(model, x):\n",
        "    preds = model.predict(x)\n",
        "    # print(type(model.output[0]))\n",
        "    # print((model.output[0]))\n",
        "    # print((model.output[1]))\n",
        "    # print((model.output[2]))\n",
        "    # print(model.output)\n",
        "\n",
        "    max_output = model.output[np.argmax(preds)]\n",
        "    conv = model.layers[0]\n",
        "    last_conv_layer = conv.get_layer('block5_conv3')\n",
        "    grads = K.gradients(max_output, last_conv_layer.output)\n",
        "    pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
        "    iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
        "    pooled_grads_value, conv_layer_output_value = iterate([x])\n",
        "\n",
        "    for i in range(512):\n",
        "        conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
        "    heatmap = np.mean(conv_layer_output_value, axis=-1)\n",
        "    heatmap = np.maximum(heatmap, 0)\n",
        "    heatmap /= np.max(heatmap)\n",
        "    return heatmap, conv_layer_output_value, pooled_grads_value\n",
        "\n",
        "\n",
        "# model = VGG16(weights=\"imagenet\")\n",
        "\n",
        "heatmap, conv_output, pooled_grads = gradCAM(model, img_tensor)\n",
        "\n",
        "img = cv2.imread(img_path)\n",
        "heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "heatmap = np.uint8(255*heatmap)\n",
        "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "superimposed_img = heatmap*0.4 + img\n",
        "cv2.imwrite('americano.jpg', superimposed_img)\n",
        "\n",
        "draw_no = range(256, 256+32, 1)\n",
        "conv_activation = np.expand_dims(conv_output[:, :, draw_no], axis=0)\n",
        "draw_activation(conv_activation, 'last_conv')\n",
        "plt.matshow(pooled_grads[draw_no].reshape(-1, 16), cmap='viridis')\n",
        "\n",
        "plt.savefig('Americano.jpg')"
      ]
    }
  ]
}